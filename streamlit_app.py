import streamlit as st
import pandas as pd
import plotly.express as px
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from catboost import CatBoostClassifier
import numpy as np


st.title('üå¶Ô∏è –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ø–æ–≥–æ–¥—ã')

st.write('–ó–¥–µ—Å—å –º—ã –æ–±—É—á–∏–º –º–æ–¥–µ–ª—å –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ç–∏–ø–∞ –ø–æ–≥–æ–¥—ã.')

# --- –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö ---
file_path = https://raw.githubusercontent.com/TcrewJamik/MyProject1/refs/heads/master/weather_classification_data.csv
df = pd.read_file(file_path)

with st.expander('–î–∞–Ω–Ω—ã–µ'):
    st.write("X")
    X_raw = df.drop('Weather Type', axis=1)
    st.dataframe(X_raw)

    st.write("y")
    y_raw = df['Weather Type']
    st.dataframe(y_raw)

# --- –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å ---
with st.sidebar:
    st.header("–í–≤–µ–¥–∏—Ç–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ–≥–æ–¥—ã: ")
    temperature = st.slider('Temperature', -25.0, 45.0, 15.0)
    humidity = st.slider('Humidity', 20, 100, 60)
    wind_speed = st.slider('Wind Speed', 0.0, 25.0, 5.0)
    precipitation = st.slider('Precipitation (%)', 0.0, 100.0, 0.0)
    cloud_cover = st.selectbox('Cloud Cover', ('partly cloudy', 'sunny', 'cloudy'))
    atmospheric_pressure = st.slider('Atmospheric Pressure', 980.0, 1030.0, 1013.0)
    uv_index = st.slider('UV Index', 0, 10, 2)
    season = st.selectbox('Season', ('Spring', 'Summer', 'Autumn', 'Winter'))
    visibility = st.slider('Visibility (km)', 0.0, 20.0, 10.0)
    location = st.selectbox('Location', ('London', 'New York', 'Tokyo', 'Sydney', 'Dubai'))

# --- –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö ---
st.subheader('–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö')

fig = px.scatter(
    df,
    x='Temperature',
    y='Humidity',
    color='Season',
    title='–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ vs. –í–ª–∞–∂–Ω–æ—Å—Ç—å –ø–æ —Å–µ–∑–æ–Ω–∞–º'
)
st.plotly_chart(fig)

fig2 = px.histogram(
    df,
    x='Wind Speed',
    nbins=30,
    title='–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏ –≤–µ—Ç—Ä–∞'
)
st.plotly_chart(fig2)

# --- –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö ---

# 1. –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤ (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ 99-–º –ø—Ä–æ—Ü–µ–Ω—Ç–∏–ª–µ–º)
for col in ['Temperature', 'Humidity', 'Precipitation (%)', 'Atmospheric Pressure']:
    cap = df[col].quantile(0.99)
    df[col] = df[col].clip(upper=cap)

# 2. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
y = df['Weather Type']
X = df.drop('Weather Type', axis=1)

# 3. –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y)

# 4. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö (—Ç–æ–ª—å–∫–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 5. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —á–∏—Å–ª–æ–≤—ã—Ö –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
numerical_features = ['Temperature', 'Humidity', 'Wind Speed', 'Precipitation (%)', 'Atmospheric Pressure', 'UV Index', 'Visibility (km)']
categorical_features = ['Cloud Cover', 'Season', 'Location']

# --- –°–æ–∑–¥–∞–Ω–∏–µ –≤—Ö–æ–¥–Ω–æ–≥–æ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞ ---
data = {
    'Temperature': temperature,
    'Humidity': humidity,
    'Wind Speed': wind_speed,
    'Precipitation (%)': precipitation,
    'Cloud Cover': cloud_cover,
    'Atmospheric Pressure': atmospheric_pressure,
    'UV Index': uv_index,
    'Season': season,
    'Visibility (km)': visibility,
    'Location': location
}
input_df = pd.DataFrame(data, index=[0])

# --- –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ X ---

# One-Hot Encoding –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
ohe = OneHotEncoder(handle_unknown='ignore')
encoded_categorical_features = ohe.fit_transform(df[categorical_features]).toarray()
X_encoded = pd.DataFrame(encoded_categorical_features, columns=ohe.get_feature_names_out(categorical_features))
X = pd.concat([df[numerical_features].reset_index(drop=True), X_encoded], axis=1)

encoded_input_categorical = ohe.transform(input_df[categorical_features]).toarray()
input_encoded = pd.DataFrame(encoded_input_categorical, columns=ohe.get_feature_names_out(categorical_features))
input_row = pd.concat([input_df[numerical_features].reset_index(drop=True), input_encoded], axis=1)

# –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
scaler = StandardScaler()
X[numerical_features] = scaler.fit_transform(X[numerical_features])
input_row[numerical_features] = scaler.transform(input_row[numerical_features]) #–ø—Ä–∏–º–µ–Ω—è–µ–º –∫ –≤—Ö–æ–¥—è—â–∏–º –¥–∞–Ω–Ω—ã–º

with st.expander('–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö'):
    st.write('**–í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–Ω–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞)**')
    st.dataframe(input_row)
    st.write('**–û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ + –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)**')
    st.dataframe(pd.concat([input_row, pd.DataFrame(X, columns=input_row.columns)], axis=0))
    st.write('**–¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è (y)**')
    st.write(y)

# --- –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ ---
st.subheader('–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏')

# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è Grid Search
param_grid_rf = {
    'n_estimators': [50, 100],
    'max_depth': [None, 5, 10]
}
param_grid_knn = {
    'n_neighbors': [3, 5, 7]
}
param_grid_catboost = {
    'iterations': [50, 100],
    'learning_rate': [0.01, 0.1],
    'depth': [4, 6]
}

# Base models
base_rf = RandomForestClassifier(random_state=42)
base_knn = KNeighborsClassifier()
base_catboost = CatBoostClassifier(random_seed=42, logging_level='Silent')

# Perform grid search for each model
grid_search_rf = GridSearchCV(base_rf, param_grid_rf, cv=3, scoring='accuracy', n_jobs=-1)
grid_search_rf.fit(X, y)

grid_search_knn = GridSearchCV(base_knn, param_grid_knn, cv=3, scoring='accuracy', n_jobs=-1)
grid_search_knn.fit(X, y)

grid_search_catboost = GridSearchCV(base_catboost, param_grid_catboost, cv=3, scoring='accuracy', n_jobs=-1)
grid_search_catboost.fit(X, y)

# Find the best model based on accuracy
best_rf = grid_search_rf.best_estimator_
best_knn = grid_search_knn.best_estimator_
best_catboost = grid_search_catboost.best_estimator_

models = {
    'Random Forest': best_rf,
    'K-Nearest Neighbors': best_knn,
    'CatBoost': best_catboost
}

best_model_name = max(models, key=lambda k: cross_val_score(models[k], X, y, cv=3).mean())
best_model = models[best_model_name]
best_params = {}
if best_model_name == 'Random Forest':
    best_params = grid_search_rf.best_params_
elif best_model_name == 'K-Nearest Neighbors':
    best_params = grid_search_knn.best_params_
elif best_model_name == 'CatBoost':
    best_params = grid_search_catboost.best_params_

st.write(f"**–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å:** {best_model_name}")
st.write(f"**–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:** {best_params}")

# --- –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ ---
prediction = best_model.predict(input_row)
prediction_proba = best_model.predict_proba(input_row)

# --- –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ---
st.subheader('–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è')

# Assuming your label encoder has a classes_ attribute
weather_types = label_encoder.classes_

# Create a DataFrame for the prediction probabilities
df_prediction_proba = pd.DataFrame(prediction_proba, columns=weather_types)

st.write('**–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞ –ø–æ–≥–æ–¥—ã:**')
st.dataframe(
    df_prediction_proba,
    column_config={
        weather_type: st.column_config.ProgressColumn(
            weather_type,
            format='%f',
            width='medium',
            min_value=0,
            max_value=1
        ) for weather_type in weather_types
    },
    hide_index=True
)

# Map prediction index back to weather type name
predicted_weather_type = weather_types[prediction[0]]

st.success(f"–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ–º—ã–π —Ç–∏–ø –ø–æ–≥–æ–¥—ã: **{predicted_weather_type}**")
